{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f48c48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf2ade",
   "metadata": {},
   "source": [
    "# Data Processing Steps\n",
    "\n",
    "First, you are asked to write code to perform the following data processing steps:\n",
    "1. Converting the EOD data into five separate time series data frames; one\n",
    "each for Open, High, Low, Close and Volume. In each data frame, rows\n",
    "should be indexed by date, and columns by ticker.\n",
    "2. Create a data frame containing the future close returns as defined by Eq.\n",
    "(1), in the same format. Also create a data frame containing close returns.\n",
    "3. Create a data frame containing the ratios of High\n",
    "Low\n",
    "for each ticker each\n",
    "day, in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aeae24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all csv files and append them into one dataframe.\n",
    "\n",
    "path =\"ASX-2015-2018\"\n",
    "#we shall store all the file names in this list\n",
    "filelist = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        #append the file name to the list\n",
    "        filelist.append(os.path.join(root,file))\n",
    "\n",
    "        \n",
    "list_of_dataframes = []\n",
    "#print allhe file names\n",
    "for name in filelist:\n",
    "    list_of_dataframes.append(pd.read_csv(name, index_col=\"Date\", parse_dates=True, names=[\"Ticker\", \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]))\n",
    "    \n",
    "merged_df = pd.concat(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f4db4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_pickle(\"merged.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89099aa9",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "48a2b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_df = merged_df[[\"Ticker\", \"Open\"]]\n",
    "high_df = merged_df[[\"Ticker\", \"High\"]]\n",
    "low_df = merged_df[[\"Ticker\", \"Low\"]]\n",
    "close_df = merged_df[[\"Ticker\", \"Close\"]]\n",
    "volume_df = merged_df[[\"Ticker\", \"Volume\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "58cc37f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>1PG</td>\n",
       "      <td>607639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>3PL</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>8IH</td>\n",
       "      <td>112700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>AAA</td>\n",
       "      <td>409863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>AAC</td>\n",
       "      <td>90150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>XTJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>XTL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>XTO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>XUJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>XXJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319997 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ticker  Volume\n",
       "Date                     \n",
       "2015-01-02    1PG  607639\n",
       "2015-01-02    3PL    1863\n",
       "2015-01-02    8IH  112700\n",
       "2015-01-02    AAA  409863\n",
       "2015-01-02    AAC   90150\n",
       "...           ...     ...\n",
       "2018-06-29    XTJ       0\n",
       "2018-06-29    XTL       0\n",
       "2018-06-29    XTO       0\n",
       "2018-06-29    XUJ       0\n",
       "2018-06-29    XXJ       0\n",
       "\n",
       "[1319997 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "87340647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_tickers(df, data_type):\n",
    "    #Return a list of unique tickers\n",
    "\n",
    "    #Parameters:\n",
    "    #    df (pandas DataFrame):Dataframe with combined tickers\n",
    "    #    data_type (str):Data description in the df column\n",
    "\n",
    "    #Returns:\n",
    "    #    uniquedf_list (list):List with unique ticker df\n",
    "    \n",
    "    \n",
    "    tickers = pd.unique(df['Ticker'])\n",
    "    uniquedf_list = []\n",
    "    for ticker in tickers:\n",
    "        unique_df = df[df['Ticker'] == ticker]\n",
    "        unique_df = pd.DataFrame(unique_df[data_type].rename(ticker))\n",
    "        uniquedf_list.append(unique_df)\n",
    "        \n",
    "    return uniquedf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bcd034ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dfs(df_list):\n",
    "    #Return a concatenated by column dataframe\n",
    "\n",
    "    #Parameters:\n",
    "    #    df_list (list of pandas DataFrame):List with unique ticker df\n",
    "\n",
    "    #Returns:\n",
    "    #    main_df (pd.DataFrame):Concatenated dataframe by column\n",
    "    main_df = pd.DataFrame()\n",
    "    for df in df_list:\n",
    "        main_df = pd.concat([main_df, df], axis=1)\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3c6e4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(df_list, type_list):\n",
    "    for index in range(len(df_list)):\n",
    "        tickerdf_list = unique_tickers(df_list[index], type_list[index])\n",
    "        \n",
    "        final_df = pd.DataFrame()\n",
    "        \n",
    "        final_df = concat_dfs(tickerdf_list)\n",
    "        final_df.to_pickle(\"{}.pkl\".format(type_list[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2c2faacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_list = [open_df, high_df, low_df, close_df, volume_df]\n",
    "type_list = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "data_processing(df_list, type_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278baab",
   "metadata": {},
   "source": [
    "Note: Could have used pandas.Pivot() for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd21bc",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2c63b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open(\"Open.pkl\",'rb')\n",
    "open_df = pickle.load(open_file)\n",
    "\n",
    "high_file = open(\"High.pkl\",'rb')\n",
    "high_df = pickle.load(high_file)\n",
    "\n",
    "low_file = open(\"Low.pkl\",'rb')\n",
    "low_df = pickle.load(low_file)\n",
    "\n",
    "close_file = open(\"Close.pkl\",'rb')## Step 1\n",
    "close_df = pickle.load(close_file)\n",
    "\n",
    "volume_file = open(\"Volume.pkl\",'rb')\n",
    "volume_df = pickle.load(volume_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d7e41",
   "metadata": {},
   "source": [
    "pd.DataFrame.pct_change(1) is the same as the formula as defined by Eq. (1).\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0d166e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_return1_df = close_df.pct_change(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "959e02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_return1_df\n",
    "future_return1_df.to_pickle(\"future_return1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "64cb0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_return_df = close_df / open_df -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9062de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_return_df\n",
    "close_return_df.to_pickle(\"close_return.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2227a22",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b7088f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low_df = high_df / low_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "451888e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low_df\n",
    "high_low_df.to_pickle(\"high_low.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d873a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c16740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_change_lag1_df = volume_df.pct_change(periods=1)\n",
    "\n",
    "volume_change_lag1_df = volume_change_lag1_df.shift(periods=1)\n",
    "\n",
    "volume_change_lag1_df.to_pickle(\"volume_change_lag1.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
